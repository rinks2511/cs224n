<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content=on><![endif]--><title>A Latent Variable Model Approach to PMI-based Word Embeddings - ACL Anthology</title><meta name=generator content="Hugo 0.58.3"><link href=/anthology/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/anthology/css/main.min.200d01a437e018e54153eeb07703db6e7eb464678ee371b16b2bc878cbd696af.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/anthology/css/academicons.min.css><meta content="A Latent Variable Model Approach to PMI-based Word Embeddings" name=citation_title><meta content="Sanjeev Arora" name=citation_author><meta content="Yuanzhi Li" name=citation_author><meta content="Yingyu Liang" name=citation_author><meta content="Tengyu Ma" name=citation_author><meta content="Andrej Risteski" name=citation_author><meta content="Transactions of the Association for Computational Linguistics" name=citation_journal_title><meta content=4 name=citation_volume><meta content=2016 name=citation_publication_date><meta content=https://www.aclweb.org/anthology/Q16-1028.pdf name=citation_pdf_url><meta content=385 name=citation_firstpage><meta content=399 name=citation_lastpage><meta content=10.1162/tacl_a_00106 name=citation_doi><meta property=og:title content="A Latent Variable Model Approach to PMI-based Word Embeddings"><meta property=og:image content=https://www.aclweb.org/anthology/thumb/Q16-1028.jpg><meta property=og:image:alt content="First page of paper PDF."><meta property=og:type content=article><meta property=og:site_name content="ACL Anthology"><meta property=og:url content=https://www.aclweb.org/anthology/Q16-1028><meta property=og:description content="Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, Andrej Risteski. Transactions of the Association for Computational Linguistics, Volume 4. 2016."><link rel=canonical href=https://www.aclweb.org/anthology/Q16-1028></head><body><nav class="navbar navbar-expand-sm navbar-light bg-light bg-gradient-light shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/anthology/><img src=/anthology/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL Anthology</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/anthology/faq/>FAQ<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/anthology/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/anthology/info/contrib/>Submissions<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/anthology/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-primary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://www.aclweb.org/anthology/Q16-1028.pdf>A Latent Variable Model Approach to <span class=acl-fixed-case>PMI</span>-based Word Embeddings</a></h2><p class=lead><a href=/anthology/people/s/sanjeev-arora/>Sanjeev Arora</a>,
<a href=/anthology/people/y/yuanzhi-li/>Yuanzhi Li</a>,
<a href=/anthology/people/y/yingyu-liang/>Yingyu Liang</a>,
<a href=/anthology/people/t/tengyu-ma/>Tengyu Ma</a>,
<a href=/anthology/people/a/andrej-risteski/>Andrej Risteski</a><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3"><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5>Semantic word embeddings represent the meaning of a word via a vector, and are created by diverse methods. Many use nonlinear operations on co-occurrence statistics, and have hand-tuned hyperparameters and reweighting methods. This paper proposes a new generative model, a dynamic version of the log-linear topic model of Mnih and Hinton (2007). The methodological novelty is to use the prior to compute closed form expressions for word statistics. This provides a theoretical justification for nonlinear models like PMI, word2vec, and GloVe, as well as some hyperparameter choices. It also helps explain why low-dimensional semantic embeddings contain linear algebraic structure that allows solution of word analogies, as shown by Mikolov et al. (2013a) and many subsequent papers. Experimental support is provided for the generative model assumptions, the most important of which is that latent word vectors are fairly uniformly dispersed in space.</div></div><dl><dt>Anthology ID:</dt><dd>Q16-1028</dd><dt>Volume:</dt><dd><a href=/anthology/volumes/Q16-1/>Transactions of the Association for Computational Linguistics, Volume 4</a></dd><dt>Month:</dt><dd></dd><dt>Year:</dt><dd>2016</dd><dt>Address:</dt><dd></dd><dt>Venue:</dt><dd><a href=/anthology/venues/tacl/>TACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd></dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>385–399</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://www.aclweb.org/anthology/Q16-1028>https://www.aclweb.org/anthology/Q16-1028</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.1162/tacl_a_00106 title="To the current version of the paper by DOI">10.1162/tacl_a_00106</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row><a class="btn btn-secondary btn-sm" href=/anthology/Q16-1028.bib>BibTeX</a>
<a class="btn btn-secondary btn-sm" href=/anthology/Q16-1028.xml>MODS XML</a>
<a class="btn btn-secondary btn-sm" href=/anthology/Q16-1028.endf>EndNote</a>
<button type=button class="btn btn-clipboard btn-secondary btn-sm d-none" data-clipboard-text='@article{arora-etal-2016-latent,
    title = "A Latent Variable Model Approach to {PMI}-based Word Embeddings",
    author = "Arora, Sanjeev  and
      Li, Yuanzhi  and
      Liang, Yingyu  and
      Ma, Tengyu  and
      Risteski, Andrej",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "4",
    year = "2016",
    url = "https://www.aclweb.org/anthology/Q16-1028",
    doi = "10.1162/tacl_a_00106",
    pages = "385--399",
    abstract = "Semantic word embeddings represent the meaning of a word via a vector, and are created by diverse methods. Many use nonlinear operations on co-occurrence statistics, and have hand-tuned hyperparameters and reweighting methods. This paper proposes a new generative model, a dynamic version of the log-linear topic model of Mnih and Hinton (2007). The methodological novelty is to use the prior to compute closed form expressions for word statistics. This provides a theoretical justification for nonlinear models like PMI, word2vec, and GloVe, as well as some hyperparameter choices. It also helps explain why low-dimensional semantic embeddings contain linear algebraic structure that allows solution of word analogies, as shown by Mikolov et al. (2013a) and many subsequent papers. Experimental support is provided for the generative model assumptions, the most important of which is that latent word vectors are fairly uniformly dispersed in space.",
}'><i class="far fa-clipboard pr-2"></i>Copy BibTeX to Clipboard</button></dd><dt>PDF:</dt><dd><a href=https://www.aclweb.org/anthology/Q16-1028.pdf>https://www.aclweb.org/anthology/Q16-1028.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://www.aclweb.org/anthology/Q16-1028.pdf title="Open PDF of 'A Latent Variable Model Approach to PMI-based Word Embeddings'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href=/anthology/Q16-1028.bib title="Export 'A Latent Variable Model Approach to PMI-based Word Embeddings' to bib format"><i class="fas fa-file-export"></i><span class="pl-2 transform-lower-sm">Bib</span><span class="d-none d-sm-inline">TeX</span></a>
<a class="btn btn-secondary" href="https://scholar.google.com/scholar?q=A&#43;Latent&#43;Variable&#43;Model&#43;Approach&#43;to&#43;PMI-based&#43;Word&#43;Embeddings" title="Search for 'A Latent Variable Model Approach to PMI-based Word Embeddings' on Google Scholar"><i class="ai ai-google-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr></section></div><footer class="bg-gradient-light py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5"><div class=container><p class="text-muted small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2021 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="text-muted small px-1">The ACL Anthology is managed and built by the <a href=/anthology/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="text-muted small px-1"><i>Site last built on 06 June 2021 at 04:48 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/df8fc8e217f2ec8c9c185f04a25cff5c684b50ac>commit df8fc8e2</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script><script>$(function(){$('[data-toggle="tooltip"]').tooltip();if($("#toggle-all-abstracts")){$("#toggle-all-abstracts").click(function(){var target=$("#toggle-all-abstracts");target.attr("disabled",true);if(target.attr("data-toggle-state")=="hide"){$(".abstract-collapse").collapse('show');target.attr("data-toggle-state","show");}else{$(".abstract-collapse").collapse('hide');target.attr("data-toggle-state","hide");}
target.attr("disabled",false);});$("#toggle-all-abstracts").attr("disabled",false);}})</script><script src=/anthology/js/clipboard.min.js></script><script>$(document).ready(function(){if(ClipboardJS.isSupported()){new ClipboardJS(".btn-clipboard");$(".btn-clipboard").removeClass("d-none");}});</script></body></html>